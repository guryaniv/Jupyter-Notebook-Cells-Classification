{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Classification - End Model (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we use the labeled data generated using snorkel in the previous notebook ([here](Classification.ipynb)) to train a supervised LSTM model that will classify a given cell source code into the relevant data-scientist workflow stage (multi-class text classification). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-6f526015707e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;31m# linear algebra\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[1;31m# data processing, CSV file I/O (e.g. pd.read_csv)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSpatialDropout1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# First let's import relevant libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.models import load_model\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "import os\n",
    "print(os.listdir(\"input/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# load our tagged Data\n",
    "data = pd.read_csv('input/input.tsv', delimiter='\\t', usecols=['Cell ID', 'Source', 'Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we'll remove cells that snorkel didn't tag\n",
    "data.dropna(subset=['Label'], how='all', inplace = True)\n",
    "data = data[data.Label != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37965</th>\n",
       "      <td>kabure_#_predicting-house-prices-xgb-rf-baggin...</td>\n",
       "      <td>df_usa = pd.read_csv(\"../input/kc_house_data.c...</td>\n",
       "      <td>Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69036</th>\n",
       "      <td>akashravichandran_#_pandas-tutorial-6_#_6</td>\n",
       "      <td>gaming_products = pd.read_csv(\"../input/things...</td>\n",
       "      <td>Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74003</th>\n",
       "      <td>gpehls_#_indexing-selecting-assigning_#_11</td>\n",
       "      <td>check_q8(reviews.loc[reviews.country=='Italy'])</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49329</th>\n",
       "      <td>llabhishekll_#_fraud-transaction-detection_#_24</td>\n",
       "      <td>fig = plt.figure()\\r\\r\\nax = fig.add_subplot(1...</td>\n",
       "      <td>Explore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68283</th>\n",
       "      <td>katerynad_#_data-exploring-part-1-indicators_#_14</td>\n",
       "      <td>['#indicators common for as many companies as ...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Cell ID  \\\n",
       "37965  kabure_#_predicting-house-prices-xgb-rf-baggin...   \n",
       "69036          akashravichandran_#_pandas-tutorial-6_#_6   \n",
       "74003         gpehls_#_indexing-selecting-assigning_#_11   \n",
       "49329    llabhishekll_#_fraud-transaction-detection_#_24   \n",
       "68283  katerynad_#_data-exploring-part-1-indicators_#_14   \n",
       "\n",
       "                                                  Source    Label  \n",
       "37965  df_usa = pd.read_csv(\"../input/kc_house_data.c...     Load  \n",
       "69036  gaming_products = pd.read_csv(\"../input/things...     Load  \n",
       "74003    check_q8(reviews.loc[reviews.country=='Italy'])     Prep  \n",
       "49329  fig = plt.figure()\\r\\r\\nax = fig.add_subplot(1...  Explore  \n",
       "68283  ['#indicators common for as many companies as ...     Prep  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's take a look at some random cells\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's take a look at the tagged data value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ea29d595-26b0-4d83-a005-853fa59f4506",
    "_uuid": "acf2450933eb3586930df738829abd2e11646e14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Explore    31813\n",
       "Prep       15344\n",
       "Eval        7897\n",
       "Load        7176\n",
       "Import      4980\n",
       "Train       3052\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now let's see\n",
    "data.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the classes are imbalanced. The data exploration class has much more cells than the others. we want to have balaced classes for the model to train, so we'll take a fixed size from each class (under sample the large classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "44de46e2-acce-470d-9c46-624cb0dd15b9",
    "_uuid": "eb9f4766b60f5a23901a8bde1d901ced6c7a3b3e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>shelars1985_#_bitcoin-vs-ethereum-candlestick-...</td>\n",
       "      <td>['f,ax=plt.subplots(figsize=(15,11))\\n', 'ax.x...</td>\n",
       "      <td>Explore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50910</th>\n",
       "      <td>asindico_#_porto-seguro-the-essential-kickstar...</td>\n",
       "      <td>[\"tmp = pd.concat([df['target'],df[ind_con]],a...</td>\n",
       "      <td>Explore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42821</th>\n",
       "      <td>alaeddineayadi_#_neural-net-solution-with-kera...</td>\n",
       "      <td>['#KERAS MODEL DEFINITION\\n', 'from keras.laye...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26280</th>\n",
       "      <td>kerneler_#_starter-govdata360-998ff914-e_#_4</td>\n",
       "      <td># Correlation matrix\\r\\r\\r\\ndef plotCorrelatio...</td>\n",
       "      <td>Explore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24555</th>\n",
       "      <td>xavierbourretsicotte_#_localizing-utc-time-eda...</td>\n",
       "      <td>from pandas.io.json import json_normalize\\r\\r\\...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Cell ID  \\\n",
       "886    shelars1985_#_bitcoin-vs-ethereum-candlestick-...   \n",
       "50910  asindico_#_porto-seguro-the-essential-kickstar...   \n",
       "42821  alaeddineayadi_#_neural-net-solution-with-kera...   \n",
       "26280       kerneler_#_starter-govdata360-998ff914-e_#_4   \n",
       "24555  xavierbourretsicotte_#_localizing-utc-time-eda...   \n",
       "\n",
       "                                                  Source    Label  \n",
       "886    ['f,ax=plt.subplots(figsize=(15,11))\\n', 'ax.x...  Explore  \n",
       "50910  [\"tmp = pd.concat([df['target'],df[ind_con]],a...  Explore  \n",
       "42821  ['#KERAS MODEL DEFINITION\\n', 'from keras.laye...    Train  \n",
       "26280  # Correlation matrix\\r\\r\\r\\ndef plotCorrelatio...  Explore  \n",
       "24555  from pandas.io.json import json_normalize\\r\\r\\...     Prep  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first we shuffle the data by randomly re-indexing\n",
    "shuffled = data.reindex(np.random.permutation(data.index))\n",
    "shuffled.head(5) #check data is indeed shuffeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barneythedinosaur_#_homework3_#_2</td>\n",
       "      <td>data=pd.read_csv('../input/kc_house_data.csv')...</td>\n",
       "      <td>Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rahulin05_#_predicting-house-sales-by-linear-r...</td>\n",
       "      <td>['import pandas as pd\\n', 'housing_data = pd.r...</td>\n",
       "      <td>Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shinto_#_notebook2_#_21</td>\n",
       "      <td>['submission = pd.read_csv(\"../input/sample_su...</td>\n",
       "      <td>Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>piscab_#_classifying-narratives-by-product-w-c...</td>\n",
       "      <td>['# Read the input dataset \\n', 'd = pd.read_c...</td>\n",
       "      <td>Load</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shivammittal99_#_renaming-and-combining-workbo...</td>\n",
       "      <td>powerlifting_meets = pd.read_csv(\"../input/pow...</td>\n",
       "      <td>Load</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Cell ID  \\\n",
       "0                  barneythedinosaur_#_homework3_#_2   \n",
       "1  rahulin05_#_predicting-house-sales-by-linear-r...   \n",
       "2                            shinto_#_notebook2_#_21   \n",
       "3  piscab_#_classifying-narratives-by-product-w-c...   \n",
       "4  shivammittal99_#_renaming-and-combining-workbo...   \n",
       "\n",
       "                                              Source Label  \n",
       "0  data=pd.read_csv('../input/kc_house_data.csv')...  Load  \n",
       "1  ['import pandas as pd\\n', 'housing_data = pd.r...  Load  \n",
       "2  ['submission = pd.read_csv(\"../input/sample_su...  Load  \n",
       "3  ['# Read the input dataset \\n', 'd = pd.read_c...  Load  \n",
       "4  powerlifting_meets = pd.read_csv(\"../input/pow...  Load  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_class_size = 5000 #the fixed size was selected by trial and error\n",
    "l  = shuffled[shuffled['Label'] == 'Load'][:fixed_class_size]\n",
    "p  = shuffled[shuffled['Label'] == 'Prep'][:fixed_class_size]\n",
    "t  = shuffled[shuffled['Label'] == 'Train'][:fixed_class_size]\n",
    "ev = shuffled[shuffled['Label'] == 'Eval'][:fixed_class_size]\n",
    "ex = shuffled[shuffled['Label'] == 'Explore'][:fixed_class_size]\n",
    "i  = shuffled[shuffled['Label'] == 'Import'][:fixed_class_size]\n",
    "\n",
    "concated = pd.concat([l, p, t, ev, ex, i], ignore_index=True) #our new data with balanced classes\n",
    "concated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11660</th>\n",
       "      <td>shenba_#_home-credit-v6-12jun2018_#_80</td>\n",
       "      <td>num_round = 1000\\r\\r\\nbst = xgb.train(params, ...</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>finlay_#_quick-algos-start_#_5</td>\n",
       "      <td>['from sklearn.linear_model import LinearRegre...</td>\n",
       "      <td>Eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>bill10_#_health-insurance-marketplace_#_5</td>\n",
       "      <td>[\"df.loc[df.IndividualRate==0, 'IndividualRate...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>optidatascience_#_data-preparation-for-sberban...</td>\n",
       "      <td>[\"dt = 'object'\\n\", 'sel_col = train.columns[t...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>rveldur_#_mercari-price-suggestion-data-mining...</td>\n",
       "      <td>full_df[\"category_name\"] = full_df[\"category_n...</td>\n",
       "      <td>Prep</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Cell ID  \\\n",
       "11660             shenba_#_home-credit-v6-12jun2018_#_80   \n",
       "14052                     finlay_#_quick-algos-start_#_5   \n",
       "7378           bill10_#_health-insurance-marketplace_#_5   \n",
       "6335   optidatascience_#_data-preparation-for-sberban...   \n",
       "9245   rveldur_#_mercari-price-suggestion-data-mining...   \n",
       "\n",
       "                                                  Source  Label  \n",
       "11660  num_round = 1000\\r\\r\\nbst = xgb.train(params, ...  Train  \n",
       "14052  ['from sklearn.linear_model import LinearRegre...   Eval  \n",
       "7378   [\"df.loc[df.IndividualRate==0, 'IndividualRate...   Prep  \n",
       "6335   [\"dt = 'object'\\n\", 'sel_col = train.columns[t...   Prep  \n",
       "9245   full_df[\"category_name\"] = full_df[\"category_n...   Prep  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shuffle the dataset again by re-indexing\n",
    "concated = concated.reindex(np.random.permutation(concated.index))\n",
    "concated.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Vector representation of label and code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll represent the label as a one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "2d3da0fd-6d73-4f3b-b06b-d2bba34bbd4a",
    "_uuid": "60febe37826f220106adf69a51dad124cfae45cc",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_categorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d47db35769dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#one-hot encode the label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'INT'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'Label'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconcated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mconcated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'to_categorical' is not defined"
     ]
    }
   ],
   "source": [
    "#add int representation of the label\n",
    "concated['INT'] = 0\n",
    "concated.loc[concated['Label'] == 'Load', 'INT']  = 0\n",
    "concated.loc[concated['Label'] == 'Prep', 'INT']  = 1\n",
    "concated.loc[concated['Label'] == 'Train', 'INT']  = 2\n",
    "concated.loc[concated['Label'] == 'Eval', 'INT'] = 3\n",
    "concated.loc[concated['Label'] == 'Explore', 'INT'] = 4\n",
    "concated.loc[concated['Label'] == 'Import', 'INT']  = 5\n",
    "\n",
    "#one-hot encode the label\n",
    "labels = to_categorical(concated['INT'], num_classes=6)\n",
    "if 'Label' in concated.keys():\n",
    "    concated.drop(['Label'], axis=1)\n",
    "# '''\n",
    "#  [1. 0. 0. 0. 0. 0.] load data\n",
    "#  [0. 1. 0. 0. 0. 0.] data preparation and cleaning\n",
    "#  [0. 0. 1. 0. 0. 0.] model training and parameter tuning\n",
    "#  [0. 0. 0. 1. 0. 0.] model evaluation\n",
    "#  [0. 0. 0. 0. 1. 0.] data exploration\n",
    "#  [0. 0. 0. 0. 0. 1.] imports\n",
    "# '''\n",
    "\n",
    "#let's print some of the labels to see the encoding\n",
    "labels.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all comments, as comments may refer to actions that weren’t really done or to what was done previously to the current cell, so that it just interferes in our task to classify the current cell correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Label</th>\n",
       "      <th>INT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11660</th>\n",
       "      <td>shenba_#_home-credit-v6-12jun2018_#_80</td>\n",
       "      <td>num_round = 1000\\r\\r\\nbst = xgb.train(params, ...</td>\n",
       "      <td>Train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14052</th>\n",
       "      <td>finlay_#_quick-algos-start_#_5</td>\n",
       "      <td>['from sklearn.linear_model import LinearRegre...</td>\n",
       "      <td>Eval</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7378</th>\n",
       "      <td>bill10_#_health-insurance-marketplace_#_5</td>\n",
       "      <td>[\"df.loc[df.IndividualRate==0, 'IndividualRate...</td>\n",
       "      <td>Prep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>optidatascience_#_data-preparation-for-sberban...</td>\n",
       "      <td>[\"dt = 'object'\\n\", 'sel_col = train.columns[t...</td>\n",
       "      <td>Prep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9245</th>\n",
       "      <td>rveldur_#_mercari-price-suggestion-data-mining...</td>\n",
       "      <td>full_df[\"category_name\"] = full_df[\"category_n...</td>\n",
       "      <td>Prep</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Cell ID  \\\n",
       "11660             shenba_#_home-credit-v6-12jun2018_#_80   \n",
       "14052                     finlay_#_quick-algos-start_#_5   \n",
       "7378           bill10_#_health-insurance-marketplace_#_5   \n",
       "6335   optidatascience_#_data-preparation-for-sberban...   \n",
       "9245   rveldur_#_mercari-price-suggestion-data-mining...   \n",
       "\n",
       "                                                  Source  Label  INT  \n",
       "11660  num_round = 1000\\r\\r\\nbst = xgb.train(params, ...  Train    2  \n",
       "14052  ['from sklearn.linear_model import LinearRegre...   Eval    3  \n",
       "7378   [\"df.loc[df.IndividualRate==0, 'IndividualRate...   Prep    1  \n",
       "6335   [\"dt = 'object'\\n\", 'sel_col = train.columns[t...   Prep    1  \n",
       "9245   full_df[\"category_name\"] = full_df[\"category_n...   Prep    1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.utils import findAndRemoveComments\n",
    "concated['Source'] = concated['Source'].apply(lambda x: findAndRemoveComments(x))\n",
    "concated.head(5) # just to check comments were indeed removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn the code to-lower, filter special chars and dots and split each cell's code into tokens.\n",
    "Then we represent the most common words by ints and each cell is represented as a vector of ints according to the words that it contains. The vectors are then padded to a fixed max length of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40e6281c-2588-4ad0-991c-3d8d40791254",
    "_uuid": "0aa67be64bd63cf4350ce3f62d42c687b3143088",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_most_common_words = 8000\n",
    "max_len = 120\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,.-/:;<=>?@[\\]^`{|}~\\n\\r\\t \\'', lower=True)\n",
    "tokenizer.fit_on_texts(concated['Source'].values)\n",
    "sequences = tokenizer.texts_to_sequences(concated['Source'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "print(\"-------\")\n",
    "print(word_index) #our \"words\" dictionary\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data, represented as vectors, into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2ca496ca-4bb7-40de-bf69-d86b521af51f",
    "_uuid": "97226bf26ef141c228a1123e125ef7966612db47"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we setup and train an LSTM model using the vector representation of the code and the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e5bcf7a-4c6b-44fc-963d-415b9338abe4",
    "_uuid": "28940e621602cfd9645a88dd43427b2431c75b5b"
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "# we set an EarlyStopping, so when the model stops improving val_loss'wise it will stop training\n",
    "# but we also don't want to overfit\n",
    "emb_dim = 512\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Setup and Training\n",
    "***Note: model training could take up to 100 minutes, you can skip and load the trained model in the next cell***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79a42a6f-01f4-4e74-b645-321f2a0a6e39",
    "_uuid": "f50c8494777ca5141da8c23bb932e531a82b89d5"
   },
   "outputs": [],
   "source": [
    "print(\"(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\")\n",
    "print((X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_most_common_words, emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.8))\n",
    "model.add(LSTM(64, dropout=0.8, recurrent_dropout=0.8))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc', mean_squared_error])\n",
    "print(model.summary())\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_acc',patience=7, min_delta=0.0001)])\n",
    "# Loss: 0.614,  Accuracy: 0.815, bad conv. on 20 epochs\n",
    "# Loss: 0.593,  Accuracy: 0.816, bad conv. on 15\n",
    "# Loss: 0.577,  Accuracy: 0.814, bad conv. on 12\n",
    "# Loss: 0.584,  Accuracy: 0.800, better conv. still bad on 8\n",
    "# Loss: 0.571,  Accuracy: 0.802, better conv. still bad on 7\n",
    "# Loss: 0.599,  Accuracy: 0.793, pretty good conv. on 5 (best on 4)\n",
    "# Loss: 0.621,  Accuracy: 0.783,\n",
    "# all above with 0.6 dropouts\n",
    "# with 0.8 dropouts:\n",
    "# Loss: 0.684, Accuracy: 0.765, pretty good conv. but not yet on 8\n",
    "# Loss: 0.609, Accuracy: 0.793, good conv. on 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('LSTM.h5') #save the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load the trained model (continue here if you don't train the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trained model (not needed if you train again)\n",
    "model = load_model('LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fa53cfb9-75f7-47ee-b53d-b7f241ee082a",
    "_uuid": "a16c336b7eae3d72c7c92cf799702eacf70677c7"
   },
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a Categorical Accuracy of 79.3% - that means we get the class right for 79.3% of the cells, not bad.\n",
    "We could see during training that the MSE of the training set is similar to that of the validation set, so we figure the model isn't too overfitted.\n",
    "We optimised the model by Categorical Cross-Entropy Loss as we are classifying with softmax output node activation.\n",
    "We Can see the model convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1130440c-dd13-4f36-9657-01b13f322efb",
    "_uuid": "f8400fe47eebbb7e8456d6f3617c6bcd7eccecf6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the loss and accuracy of the trainning set cenverges to that of the validation set - as it should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll look at the model performance for each class (and also at the f:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "for pred_arr in test_pred:\n",
    "    pred = np.argmax(pred_arr)\n",
    "    y_pred.append(pred)\n",
    "    \n",
    "for true_arr in y_test:\n",
    "    true = np.argmax(true_arr)\n",
    "    y_true.append(true)\n",
    "    \n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model performs pretty well for all labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples, we can see that the model classifies correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9af38e60-0811-485d-8da3-32a744b53365",
    "_uuid": "25ba8e0b354451cc482a93324e42781fde6d0826"
   },
   "outputs": [],
   "source": [
    "code = [\"model = KNeighborsClassifier(n_neighbors=3)\\n model.fit(x, y)\"]\n",
    "seq = tokenizer.texts_to_sequences(code)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "labels = ['Load', 'Prep', 'Train', 'Eval', 'Explore', 'Import']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [\"import library\\nimport otherlibrary\"]\n",
    "seq = tokenizer.texts_to_sequences(code)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [\"df = pd.read_csv('file')\"]\n",
    "seq = tokenizer.texts_to_sequences(code)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [\"df.shape\\ndf.head()\"]\n",
    "seq = tokenizer.texts_to_sequences(code)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [\"accr = model.evaluate(X_test,y_test) print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\"]\n",
    "seq = tokenizer.texts_to_sequences(code)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try yourself by enetering a cells code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = [\"INSERT CODE HERE\"]\n",
    "seq = tokenizer.texts_to_sequences(code)\n",
    "padded = pad_sequences(seq, maxlen=max_len)\n",
    "pred = model.predict(padded)\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snorkel)",
   "language": "python",
   "name": "snorkel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
